Changed directory to /home/jhb57/dnn-information.

JobID: 10301156
======
Time: Wed 27 Mar 16:24:01 GMT 2019
Running on master node: gpu-e-74
Current directory: /home/jhb57/dnn-information

Nodes allocated:
================
gpu-e-74 gpu-e-75

numtasks=8, numnodes=2, mpi_tasks_per_node=4 (OMP_NUM_THREADS=1)

Executing command:
==================
python /home/jhb57/dnn-information/experiments/run_experiment_1.py 

Script started at 2019-03-27 16:24:07.084580
appending /home/jhb57/dnn-information/models/unet
*******************
TESTING SMALL SCALE
*******************
Initialisation time 1.239 secs

Running smoothing type none at 2019-03-27 16:24:08.323168 

Appending /home/jhb57/dnn-information
Loading images
Data shape (110, 768, 512)
Label shape (110, 2, 768, 512)
No cleaning in data load
Loaded.
len trainset 11
len testset 3
Info layers numbers [0, 6, 12, 18, 24, 30, 36, 42, 48, 54]
Let's use 4 GPUs!
Moving model to cuda:0
Updating at img [  0  17  35  88 123 158 167]
Updating to lrs [1.000000e-04 5.000000e-05 2.500000e-05 1.250000e-05 1.562500e-06
 3.906250e-07 1.953125e-07]
Starting training.
UPDATING LR 0.0001
No smoothing applied. One hot:
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Using one hot
 tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
ENTERING loss cleaning.
Cleaning by ignoring loss
[1,     2] loss / pixel: 13.40082
UPDATING LR 5e-05
[1,     4] loss / pixel: 12.80341
UPDATING LR 2.5e-05
[1,     6] loss / pixel: 12.17687
[1,     8] loss / pixel: 12.40064
[1,    10] loss / pixel: 12.34312
[Epoch 1 complete] mean loss / pixel: 12.571, accuracy 36.491%, dt 2019-03-27 16:24:59.998439
UPDATING LR 1.25e-05
[2,     2] loss / pixel: 12.34161
[2,     4] loss / pixel: 12.15933
UPDATING LR 1.5625e-06
[2,     6] loss / pixel: 11.69870
[2,     8] loss / pixel: 12.11940
UPDATING LR 3.90625e-07
[2,    10] loss / pixel: 12.12753
UPDATING LR 1.953125e-07
[Epoch 2 complete] mean loss / pixel: 12.045, accuracy 47.480%, dt 2019-03-27 16:25:32.341350

Training complete. Saving graphs
Testing
Image index tensor(0)

*OVERALL REPORT*

Trained on 3 test images.
Acc: 49%, CentralAcc: 22% AvgConf: 0.552 FPos: 46091180  FNeg: 46183508 CorrUnlabel: 43217004


*PER CLASS REPORT*

class0 Acc: 27% Conf: 1.072 Corr: 417579 FPos: 4192703 FNeg: 5049164 CorrUnLab: 4012761 on 764161 predicted labels (1528308 actual).
class1 Acc: 7% Conf: 0.159 Corr: 9981 FPos: 5642262 FNeg: 5678858 CorrUnLab: 5563933 on 88310 predicted labels (124906 actual).
class2 Acc: 83% Conf: 0.478 Corr: 169611 FPos: 5564006 FNeg: 3800847 CorrUnLab: 3767296 on 1966321 predicted labels (203162 actual).
class3 Acc: 0% Conf: 0.070 Corr: 92 FPos: 5670381 FNeg: 5757144 CorrUnLab: 5660449 on 10024 predicted labels (96787 actual).
class4 Acc: 0% Conf: 0.254 Corr: 412 FPos: 5674155 FNeg: 5727932 CorrUnLab: 5635331 on 39236 predicted labels (93013 actual).
class5 Acc: 0% Conf: 0.126 Corr: 2323 FPos: 5479293 FNeg: 5718141 CorrUnLab: 5432589 on 49027 predicted labels (287875 actual).
class6 Acc: 26% Conf: 0.385 Corr: 26927 FPos: 5666115 FNeg: 5226718 CorrUnLab: 5152592 on 540450 predicted labels (101053 actual).
class7 Acc: 19% Conf: 0.796 Corr: 15032 FPos: 5688278 FNeg: 5568927 CorrUnLab: 5505069 on 198241 predicted labels (78890 actual).
class8 Acc: 64% Conf: 0.486 Corr: 2084384 FPos: 2513987 FNeg: 3655777 CorrUnLab: 2486984 on 2111398 predicted labels (3253174 actual).

*EQUAL WEIGHT REPORT*

Accuracies (equal contribution) 25%
Confidence (equal contribution) 0.425
Training complete in 0.026 hrs
No previous experiments found. Creating results dict

Writing output to running results
Completed run at 2019-03-27 16:25:55.498174
Time for run 0.030 hrs

Running smoothing type uniform_fixed_eps at 2019-03-27 16:25:55.498197 

Appending /home/jhb57/dnn-information
Loading images
Data shape (110, 768, 512)
Label shape (110, 2, 768, 512)
No cleaning in data load
Loaded.
len trainset 11
len testset 3
Info layers numbers [0, 6, 12, 18, 24, 30, 36, 42, 48, 54]
Let's use 4 GPUs!
Moving model to cuda:0
Updating at img [  0  17  35  88 123 158 167]
Updating to lrs [1.000000e-04 5.000000e-05 2.500000e-05 1.250000e-05 1.562500e-06
 3.906250e-07 1.953125e-07]
Starting training.
UPDATING LR 0.0001
APPLIED uniform fixed epsilon.
argmax (256, 150 ) tensor(2, device='cuda:0')
old_hot (256, 150 ) tensor([0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0')
one_hot (256, 150 ) tensor([0.0125, 0.0125, 0.9000, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125],
       device='cuda:0')
argmax (256, 175 ) tensor(3, device='cuda:0')
old_hot (256, 175 ) tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0')
one_hot (256, 175 ) tensor([0.0125, 0.0125, 0.0125, 0.9000, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125],
       device='cuda:0')
argmax (256, 200 ) tensor(5, device='cuda:0')
old_hot (256, 200 ) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0')
one_hot (256, 200 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000, 0.0125, 0.0125, 0.0125],
       device='cuda:0')
argmax (256, 225 ) tensor(6, device='cuda:0')
old_hot (256, 225 ) tensor([0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0')
one_hot (256, 225 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000, 0.0125, 0.0125],
       device='cuda:0')
argmax (256, 250 ) tensor(8, device='cuda:0')
old_hot (256, 250 ) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
one_hot (256, 250 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000],
       device='cuda:0')
argmax (256, 275 ) tensor(8, device='cuda:0')
old_hot (256, 275 ) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
one_hot (256, 275 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000],
       device='cuda:0')
argmax (256, 300 ) tensor(8, device='cuda:0')
old_hot (256, 300 ) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
one_hot (256, 300 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000],
       device='cuda:0')
argmax (256, 325 ) tensor(8, device='cuda:0')
old_hot (256, 325 ) tensor([0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0')
one_hot (256, 325 ) tensor([0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.9000],
       device='cuda:0')
Using one hot
 tensor([0.9000, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125],
       device='cuda:0')
ENTERING loss cleaning.
Cleaning by ignoring loss
[1,     2] loss / pixel: 13.47015
UPDATING LR 5e-05
[1,     4] loss / pixel: 13.00539
UPDATING LR 2.5e-05
[1,     6] loss / pixel: 13.28210
[1,     8] loss / pixel: 12.91057
[1,    10] loss / pixel: 13.01104
[Epoch 1 complete] mean loss / pixel: 13.094, accuracy 11.285%, dt 2019-03-27 16:26:32.578620
UPDATING LR 1.25e-05
[2,     2] loss / pixel: 12.83795
[2,     4] loss / pixel: 12.48642
UPDATING LR 1.5625e-06
[2,     6] loss / pixel: 12.78497
[2,     8] loss / pixel: 12.11447
UPDATING LR 3.90625e-07
[2,    10] loss / pixel: 13.04339
UPDATING LR 1.953125e-07
[Epoch 2 complete] mean loss / pixel: 12.567, accuracy 17.155%, dt 2019-03-27 16:27:03.482233

Training complete. Saving graphs
Testing
Image index tensor(0)

*OVERALL REPORT*

Trained on 3 test images.
Acc: 16%, CentralAcc: 42% AvgConf: 0.701 FPos: 46137340  FNeg: 46137348 CorrUnlabel: 41305853


*PER CLASS REPORT*

class0 Acc: 16% Conf: 0.211 Corr: 247601 FPos: 4238856 FNeg: 3895448 CorrUnLab: 2614737 on 1871724 predicted labels (1528308 actual).
class1 Acc: 30% Conf: 0.927 Corr: 38367 FPos: 5642262 FNeg: 5276088 CorrUnLab: 5189549 on 491080 predicted labels (124906 actual).
class2 Acc: 44% Conf: 1.840 Corr: 90825 FPos: 5564006 FNeg: 5215843 CorrUnLab: 5103506 on 551325 predicted labels (203162 actual).
class3 Acc: 29% Conf: 0.682 Corr: 28185 FPos: 5670381 FNeg: 4975888 CorrUnLab: 4907286 on 791280 predicted labels (96787 actual).
class4 Acc: 0% Conf: 0.036 Corr: 10 FPos: 5674155 FNeg: 5727612 CorrUnLab: 5634609 on 39556 predicted labels (93013 actual).
class5 Acc: 82% Conf: 1.249 Corr: 238377 FPos: 5479293 FNeg: 4684433 CorrUnLab: 4634935 on 1082735 predicted labels (287875 actual).
class6 Acc: 0% Conf: 0.016 Corr: 9 FPos: 5666115 FNeg: 5745335 CorrUnLab: 5644291 on 21833 predicted labels (101053 actual).
class7 Acc: 27% Conf: 0.435 Corr: 21362 FPos: 5688278 FNeg: 5146689 CorrUnLab: 5089161 on 620479 predicted labels (78890 actual).
class8 Acc: 8% Conf: 0.046 Corr: 270941 FPos: 2513994 FNeg: 5470012 CorrUnLab: 2487779 on 297156 predicted labels (3253174 actual).

*EQUAL WEIGHT REPORT*

Accuracies (equal contribution) 26%
Confidence (equal contribution) 0.605
Training complete in 0.024 hrs
Reading in previous experiments.

Writing output to running results
Completed run at 2019-03-27 16:27:26.553379
Time for run 0.025 hrs

Running smoothing type uniform_vary_eps at 2019-03-27 16:27:26.553402 

Appending /home/jhb57/dnn-information
Loading images
Data shape (110, 768, 512)
Label shape (110, 2, 768, 512)
No cleaning in data load
Loaded.
len trainset 11
len testset 3
Info layers numbers [0, 6, 12, 18, 24, 30, 36, 42, 48, 54]
Let's use 4 GPUs!
Moving model to cuda:0
Updating at img [  0  17  35  88 123 158 167]
Updating to lrs [1.000000e-04 5.000000e-05 2.500000e-05 1.250000e-05 1.562500e-06
 3.906250e-07 1.953125e-07]
Starting training.
UPDATING LR 0.0001
Epsilon varied, e.g.:
 [0.11911038 0.36013514 0.47678232 0.75511684 0.86561037 0.30731813
 0.76721434 0.62520915 0.1080163 ]
Smoothing varied eps into all classes
 [0.0148888 0.0148888 0.0148888 0.0148888 0.0148888 0.0148888 0.0148888
 0.0148888]
Smoothing varied eps into all classes
 [0.04501689 0.04501689 0.04501689 0.04501689 0.04501689 0.04501689
 0.04501689 0.04501689]
Smoothing varied eps into all classes
 [0.05959779 0.05959779 0.05959779 0.05959779 0.05959779 0.05959779
 0.05959779 0.05959779]
Smoothing varied eps into all classes
 [0.09438961 0.09438961 0.09438961 0.09438961 0.09438961 0.09438961
 0.09438961 0.09438961]
Smoothing varied eps into all classes
 [0.1082013 0.1082013 0.1082013 0.1082013 0.1082013 0.1082013 0.1082013
 0.1082013]
Smoothing varied eps into all classes
 [0.03841477 0.03841477 0.03841477 0.03841477 0.03841477 0.03841477
 0.03841477 0.03841477]
Smoothing varied eps into all classes
 [0.09590179 0.09590179 0.09590179 0.09590179 0.09590179 0.09590179
 0.09590179 0.09590179]
Smoothing varied eps into all classes
 [0.07815114 0.07815114 0.07815114 0.07815114 0.07815114 0.07815114
 0.07815114 0.07815114]
Smoothing varied eps into all classes
 [0.01350204 0.01350204 0.01350204 0.01350204 0.01350204 0.01350204
 0.01350204 0.01350204]
Reconstructed smoothing tensor
 [[0.88088962 0.0148888  0.0148888  0.0148888  0.0148888  0.0148888
  0.0148888  0.0148888  0.0148888 ]
 [0.04501689 0.63986486 0.04501689 0.04501689 0.04501689 0.04501689
  0.04501689 0.04501689 0.04501689]
 [0.05959779 0.05959779 0.52321768 0.05959779 0.05959779 0.05959779
  0.05959779 0.05959779 0.05959779]
 [0.09438961 0.09438961 0.09438961 0.24488316 0.09438961 0.09438961
  0.09438961 0.09438961 0.09438961]
 [0.1082013  0.1082013  0.1082013  0.1082013  0.13438963 0.1082013
  0.1082013  0.1082013  0.1082013 ]
 [0.03841477 0.03841477 0.03841477 0.03841477 0.03841477 0.69268187
  0.03841477 0.03841477 0.03841477]
 [0.09590179 0.09590179 0.09590179 0.09590179 0.09590179 0.09590179
  0.23278566 0.09590179 0.09590179]
 [0.07815114 0.07815114 0.07815114 0.07815114 0.07815114 0.07815114
  0.07815114 0.37479085 0.07815114]
 [0.01350204 0.01350204 0.01350204 0.01350204 0.01350204 0.01350204
  0.01350204 0.01350204 0.8919837 ]]
Traceback (most recent call last):
  File "/home/jhb57/dnn-information/experiments/run_experiment_1.py", line 294, in <module>
    experiment_folder, number_samples=number_samples, nth_repeat=n)
  File "/home/jhb57/dnn-information/experiments/run_experiment_1.py", line 87, in run_experiment
    experiment_folder=fn)
  File "/home/jhb57/dnn-information/models/unet/train_segment2d.py", line 190, in train
    prnt=frst)
  File "/home/jhb57/dnn-information/models/unet/training_metadata.py", line 244, in calc_loss
    gold.device).float()
RuntimeError: expand(torch.cuda.FloatTensor{[8, 8, 512, 512]}, size=[8, 512, 512]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)
slurmstepd: error: task_p_post_term: rmdir(/sys/fs/cgroup/cpuset/slurm10301156/slurm10301156.4294967294_0) failed Device or resource busy
